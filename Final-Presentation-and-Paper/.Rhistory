# contribution of variables
varImp(rpart_model) %>% kable()
# Extract accuracy from the confusion matrix
accuracy_rpart <- confusionMatrix(rpart_result, as.factor(valid$`PCOS`))$overall["Accuracy"]
kable(accuracy_rpart, align = "l")
# creating the second dataset from the original
pcos_cleaned2 <- pcos_cleaned %>%
select(`PCOS`, `Follicle_NoR`, `Follicle_NoL`, `Weight_gain`, `Skin_darkening`, `Hair_growth`)
# create some random number for reproduction
set.seed(28)
# Second Cross Validation Set-up
inTrain2 <- createDataPartition(pcos_cleaned2$`PCOS`, p=.75, list = F)
train2 <- pcos_cleaned2[inTrain2,]
valid2 <- pcos_cleaned2[-inTrain2,]
# create the second decision tree
rpart_model2 <- rpart(`PCOS` ~ ., method = "class", data = train2)
# display the decision tree
prp(rpart_model2, main = "Fig. 12 - Second Decision Tree with 6 variables", extra=1, faclen=0,  nn=T, box.palette="Blues")
# creating our prediction
rpart_result2 <- predict(rpart_model2, newdata = valid2[, !colnames(valid2) %in% "PCOS"], type = 'class')
# creating the second confusion matrix
confusionMatrix(rpart_result2, as.factor(valid2$`PCOS`))
# contribution of variables
varImp(rpart_model2) %>% kable()
# Extract accuracy from the confusion matrix
accuracy_rpart2 <- confusionMatrix(rpart_result2, as.factor(valid2$`PCOS`))$overall["Accuracy"]
kable(accuracy_rpart2, align = "l")
# create some random numbers for reproduction
set.seed(30)
# Cross Validation Set-up
rf_inTrain <- createDataPartition(pcos_cleaned$`PCOS`, p=.75, list = F)
rf_train <- pcos_cleaned[rf_inTrain,]
rf_valid <- pcos_cleaned[-rf_inTrain,]
# check the levels of PCOS using levels()
levels(rf_train$PCOS)
levels(rf_valid$PCOS)
# Convert PCOS to factor in rf_train
rf_train$PCOS <- factor(rf_train$PCOS)
# Convert PCOS to factor in rf_valid
rf_valid$PCOS <- factor(rf_valid$PCOS)
# rechecking levels again to ensure no NULL values
levels(rf_train$PCOS)
levels(rf_valid$PCOS)
# explicitly set the levels to match the levels in rf_train.
rf_valid$PCOS <- factor(rf_valid$PCOS, levels = levels(rf_train$PCOS))
levels(rf_valid$PCOS)
# # Check the length of svm_result and svm_valid$PCOS
# length_rf_result <- length(rf_result)
# length_rf_valid <- length(rf_valid$PCOS)
#
# # Print the lengths for comparison
# print(length_rf_result)
# print(length_rf_valid)
#create some random number for reproduction
set.seed(39)
# create random forest model using the training data
rf_model <- randomForest(PCOS~., rf_train)
rf_model
# prediction
rf_result <- predict(rf_model, newdata = valid[, !colnames(valid) %in% "PCOS"])
# Create a confusion matrix
confusionMatrix(data = rf_result, reference = rf_valid$PCOS)
# plot for rf_model fig 13
varImpPlot(rf_model, main="Fig. 13 - Feature importance of first random forest model")
# table for rf_model variable contribution
varImp(rf_model) %>% kable()
set.seed(321)
# Extract accuracy from the confusion matrix for the rf_model
accuracy_rf <- confusionMatrix(rf_result, valid$PCOS)$overall["Accuracy"]
accuracy_rf
# create some random numbers for reproduction
set.seed(78)
# Second RF Cross Validation Set-up
rf_inTrain2 <- createDataPartition(pcos_cleaned2$`PCOS`, p=.75, list = F)
rf_train2 <- pcos_cleaned2[rf_inTrain2,]
rf_valid2 <- pcos_cleaned2[-rf_inTrain2,]
# check the levels of PCOS using levels()
levels(rf_train2$PCOS)
levels(rf_valid2$PCOS)
# Convert PCOS to factor in rf_train
rf_train2$PCOS <- factor(rf_train2$PCOS)
# Convert PCOS to factor in rf_valid
rf_valid2$PCOS <- factor(rf_valid2$PCOS)
# rechecking levels again to ensure no NULL values
levels(rf_train2$PCOS)
levels(rf_valid2$PCOS)
# explicitly set the levels to match the levels in rf_train.
rf_valid2$PCOS <- factor(rf_valid2$PCOS, levels = levels(rf_train2$PCOS))
levels(rf_valid2$PCOS)
# # Check the length of rf_result and rf_valid$PCOS
# length_rf_result2 <- length(rf_result2)
# length_rf_valid2 <- length(rf_valid2$PCOS)
#
# # Print the lengths for comparison
# print(length_rf_result2)
# print(length_rf_valid2)
# create some random number for reproduction
set.seed(7)
# create the second random forest model using the training data from the third decision tree
rf_model2 <- randomForest(PCOS ~ Follicle_NoR + Follicle_NoL + Weight_gain + Skin_darkening + Hair_growth, data = rf_train2)
rf_model2
# creating the prediction for the third decision tree
rf_result2 <- predict(rf_model2, newdata = rf_valid2[, !colnames(rf_valid2) %in% "PCOS"])
# Convert PCOS column to factor in rf_train2 and rf_valid2
rf_train2$PCOS <- factor(rf_train2$PCOS)
rf_valid2$PCOS <- factor(rf_valid2$PCOS)
# # Check unique levels in rf_result2 and rf_valid2$PCOS
# unique_levels_result <- unique(rf_result2)
# unique_levels_valid <- unique(rf_valid2$PCOS)
#
# # Check if the levels match
# identical(unique_levels_result, unique_levels_valid)
#
# # If levels do not match, manually set levels in rf_result2 to match those in rf_valid2$PCOS
# levels(rf_result2) <- levels(rf_valid2$PCOS)
#
# Convert rf_result2 to factor and align levels with rf_valid2$PCOS
rf_result2_factor <- factor(rf_result2, levels = levels(rf_valid2$PCOS))
# Create a confusion matrix
confusionMatrix(data = rf_result2_factor, reference = rf_valid2$PCOS)
# plot for the second rf_model fig 14
varImpPlot(rf_model2, main="Fig. 14 - Feature importance of second random forest model")
# table for rf_model2 variable contribution
varImp(rf_model2) %>% kable()
# Extract accuracy from the confusion matrix for the rf_model2
accuracy_rf2 <- confusionMatrix(data = rf_result2_factor, reference = rf_valid2$PCOS)$overall["Accuracy"]
accuracy_rf2
# Set seed for reproducibility
set.seed(67)
# Train the GBM model
gbm_model <- gbm(`PCOS` ~ ., data = train, distribution = "bernoulli", n.trees = 100, interaction.depth = 4, shrinkage = 0.01, bag.fraction = 0.5)
# Predict on the validation dataset fig 15
gbm_pred <- predict(gbm_model, newdata = valid, type = "response")
# Print the summary of the trained model
summary(gbm_model, main="Fig.15 - Summary of first GBM model")
# Calculate predicted classes (0 or 1) based on the predicted probabilities
predicted_classes <- ifelse(gbm_pred > 0.5, 1, 0)
# Create confusion matrix
confusionMatrix(data = factor(predicted_classes), reference = factor(valid$`PCOS`))
# Calculate accuracy
gbm_accuracy <- sum(predicted_classes == valid$`PCOS`) / length(valid$`PCOS`)
cat("Accuracy:", gbm_accuracy)
# creating the second dataset from the original
pcos_cleaned3 <- pcos_cleaned %>%
select(`PCOS`, `Follicle_NoR`, `Follicle_NoL`, `Weight_gain`, `Skin_darkening`, `Hair_growth`)
# Set seed for reproducibility
set.seed(68)
# Cross Validation Set-up
inTrain3 <- createDataPartition(pcos_cleaned3$`PCOS`, p=.75, list = F)
train3 <- pcos_cleaned3[inTrain3,]
valid3 <- pcos_cleaned3[-inTrain3,]
# Train the GBM model
gbm_model2 <- gbm(`PCOS` ~ ., data = train3, distribution = "bernoulli", n.trees = 100, interaction.depth = 4, shrinkage = 0.01, bag.fraction = 0.5)
# Predict on the validation dataset fig 16
gbm_pred2 <- predict(gbm_model2, newdata = valid3, type = "response")
# Print the summary of the trained model
summary(gbm_model2, main="Fig.16 - Summary of second GBM model")
# Calculate predicted classes (0 or 1) based on the predicted probabilities
predicted_classes2 <- ifelse(gbm_pred2 > 0.5, 1, 0)
# Create confusion matrix
confusionMatrix(data = factor(predicted_classes2), reference = factor(valid3$`PCOS`))
# Calculate accuracy
gbm_accuracy2 <- sum(predicted_classes2 == valid3$`PCOS`) / length(valid3$`PCOS`)
cat("Accuracy:", gbm_accuracy2)
# check the levels of PCOS using levels()
levels(train$PCOS)
levels(valid$PCOS)
# Convert PCOS to factor in svm_train
train$PCOS <- factor(train$PCOS)
# Convert PCOS to factor in svm_valid
valid$PCOS <- factor(valid$PCOS)
# rechecking levels again to ensure no NULL values
levels(train$PCOS)
levels(valid$PCOS)
# checking the structure of both valid and train datasets
str(valid)
str(train)
# explicitly set the levels to match the levels in svm_train.
valid$PCOS <- factor(valid$PCOS, levels = levels(train$PCOS))
levels(valid$PCOS)
# # Check the length of svm_result and svm_valid$PCOS
# length_svm_result <- length(svm_result)
# length_svm_valid <- length(svm_valid$PCOS)
#
# # Print the lengths for comparison
# print(length_svm_result)
# print(length_svm_valid)
#create some random numbers for reproduction
set.seed(31)
# SVM
svm_model <- svm(PCOS ~ ., train)
# create prediction
svm_result <- predict(svm_model, newdata = valid)
# confusion matrix for svm
confusionMatrix(svm_result, valid$PCOS)
#plot support vector machine
#plot(svm_model, train)
# Using PCA for dimensionality reduction (assuming 'train' has multiple features)
pca_model <- prcomp(train[, -which(names(train) == "PCOS")])  # PCA on features except target
train_pca <- predict(pca_model, train)
# Plotting the reduced dimensions (first two principal components)
plot(train_pca[, 1], train_pca[, 2], col = train$PCOS, main="Fig.17 - PCA plot for SVM 1 model")
# summary of svm_result
summary(svm_result)
#Extract accuracy from the confusion matrix
accuracy_svm <- confusionMatrix(svm_result, as.factor(valid$`PCOS`))$overall["Accuracy"]
accuracy_svm
# create some random numbers for reproduction
set.seed(8)
# Cross Validation Set-up
svm_inTrain2 <- createDataPartition(pcos_cleaned2$PCOS, p=.75, list = FALSE)
svm_train2 <- pcos_cleaned2[svm_inTrain2,]
svm_valid2 <- pcos_cleaned2[-svm_inTrain2,]
# check the levels of PCOS using levels()
levels(svm_train2$PCOS)
levels(svm_valid2$PCOS)
# Convert PCOS to factor in svm_train2
svm_train2$PCOS <- factor(svm_train2$PCOS)
# Convert PCOS to factor in svm_valid2
svm_valid2$PCOS <- factor(svm_valid2$PCOS)
# rechecking levels again to ensure no NULL values
levels(svm_train2$PCOS)
levels(svm_valid2$PCOS)
# explicitly set the levels to match the levels in svm_train2
valid$PCOS <- factor(svm_valid2$PCOS, levels = levels(svm_train2$PCOS))
levels(svm_valid2$PCOS)
# # Check the length of svm_result and svm_valid$PCOS
# length_svm_result <- length(svm_result)
# length_svm_valid2 <- length(svm_valid2$PCOS)
#
# # Print the lengths for comparison
# print(length_svm_result)
# print(length_svm_valid2)
# Second SVM
svm_model2 <- svm(PCOS ~ Follicle_NoR + Follicle_NoL + Weight_gain + Skin_darkening + Hair_growth, svm_train2)
# create prediction
svm_result2 <- predict(svm_model2, newdata = svm_valid2)
# confusion matrix for svm_valid2
confusionMatrix(svm_result2, svm_valid2$PCOS)
#plot second support vector machine model
# plot(svm_model2, svm_train2)
# Using PCA for dimensionality reduction (assuming 'train' has multiple features)
pca_model2 <- prcomp(svm_train2[, -which(names(svm_train2) == "PCOS")])  # PCA on features except target
train_pca2 <- predict(pca_model, train)
# Plotting the reduced dimensions (first two principal components)
plot(train_pca2[, 1], train_pca2[, 2], col = svm_train2$PCOS, main="Fig.18 - PCA plot for SVM 2 model")
# summary of the results
summary(svm_result2)
#Extract accuracy from the confusion matrix
accuracy_svm2 <- confusionMatrix(svm_result2, svm_valid2$`PCOS`)$overall["Accuracy"]
accuracy_svm2
# create some random numbers for reproduction
set.seed(67)
# Cross Validation Set-up
nn_inTrain <- createDataPartition(pcos_cleaned$PCOS, p=.75, list = F)
nn_train <- pcos_cleaned[nn_inTrain,]
nn_valid <- pcos_cleaned[-nn_inTrain,]
# set a seed for reproducibility purposes
set.seed(19)
# create the model
# nn_model <- neuralnet(`PCOS`~.,
#                       data = nn_train,
#                       hidden = c(12, 8),  # Specify the number of hidden layers and neurons
#                       linear.output = FALSE,
#                       stepmax = 20000  # Increase the maximum number of iterations
# )
# recreate the first model:
nn_model2 <-  neuralnet(`PCOS`~.,
data=train,
hidden=c(4,1),
linear.output = FALSE,
stepmax = 10000  # Increase the maximum number of iterations
)
# create the plot based on the model above
plot(nn_model2, rep = "best")
grid::grid.text("Fig. 19.2 - First Neural Network Model", x = 0.5, y = 0.1)
# make predictions on the test data using a previously trained model
pred <- predict(nn_model2, valid)
# create a vector of labels for the two possible `PCOS(Y/N)` status in the dataset.
labels <- c("0", "1")
# creates a data frame with the column index of the maximum value in each row of the "pred" variable
prediction_label <- data.frame(max.col(pred)) %>%
# use the mutate function to add a new column to the data frame called "pred"
mutate(pred=labels[max.col.pred.]) %>%
select(2) %>%
# convert the data frame to a vector.
unlist()
# print the table
table(valid$`PCOS`, prediction_label)
#checking the accuracy
check <- as.numeric(valid$`PCOS`) == max.col(pred)
nn_accuracy <-  (sum(check)/nrow(valid))
nn_accuracy
# set a seed for reproducibility purposes
set.seed(13)
# create the second model
nn_model3 <-  neuralnet(`PCOS`~Follicle_NoL + Follicle_NoR + Hair_growth + Skin_darkening + Weight_gain,
data=train2,
hidden=c(2,1),
linear.output = FALSE,
stepmax = 10000  # Increase the maximum number of iterations
)
# create the plot based on the model above
plot(nn_model3, rep = "best", main="")
grid::grid.text("Fig. 20 -  Second Neural Network", x = .5, y = .2)
# make predictions on the test data using a previously trained model
pred2 <- predict(nn_model3, valid2)
# create a vector of labels for the two possible `PCOS` status in the dataset.
labels2 <- c("0", "1")
# creates a data frame with the column index of the maximum value in each row of the "pred" variable
prediction_label2 <- data.frame(max.col(pred2)) %>%
# use the mutate function to add a new column to the data frame called "pred"
mutate(pred2=labels2[max.col.pred2.]) %>%
select(2) %>%
# convert the data frame to a vector.
unlist()
# print the table
table(valid2$`PCOS`, prediction_label2)
# checking the accuracy
check2 <- as.numeric(valid2$`PCOS`) == max.col(pred2)
nn_accuracy2 <-  (sum(check2)/nrow(valid2))
nn_accuracy2
# Remove rows with missing values from train and valid datasets
train <- train[complete.cases(train), ]
valid <- valid[complete.cases(valid), ]
# set a seed for reproducibility purposes
set.seed(78)
# Set the value of k for kNN
k <- 5  # Change this value as needed
# Fit the kNN model using the training data
knn_model <- knn(train[, -which(names(train) == "PCOS")],
valid[, -which(names(valid) == "PCOS")],
train$`PCOS`,
k = k)
# Create confusion matrix for knn model
conf_matrix <- confusionMatrix(knn_model, valid$`PCOS`)
conf_matrix
# Plot confusion matrix
plot(conf_matrix$table, col = conf_matrix$byClass,
main = "Fig. 21 - Confusion Matrix for first kNN Model",
xlab = "Predicted",
ylab = "Actual")
# Calculate accuracy
knn_accuracy <- mean(knn_model == valid$`PCOS`)
knn_accuracy
# Filter and select the desired columns for the new dataset
pcos_cleaned4 <- pcos_cleaned %>%
select(`PCOS`, `Follicle_NoR`, `Follicle_NoL`, `Weight_gain`,
`Skin_darkening`, `Hair_growth`)
# Split the data into training and validation sets (if needed)
set.seed(123)  # Set seed for reproducibility
inTrain4 <- createDataPartition(pcos_cleaned4$`PCOS`, p = 0.75, list = FALSE)
train4 <- pcos_cleaned4[inTrain4, ]
valid4 <- pcos_cleaned4[-inTrain4, ]
# Check for missing values and remove them if present
train4 <- train4[complete.cases(train4), ]
valid4 <- valid4[complete.cases(valid4), ]
# Set the value of k for kNN
k <- 5  # Change this value as needed
# Fit the kNN model using the training data
knn_model2 <- knn(train4[, -which(names(train4) == "PCOS")],
valid4[, -which(names(valid4) == "PCOS")],
train4$`PCOS`,
k = k)
# Create confusion matrix for the second model
conf_matrix2 <- confusionMatrix(knn_model2, valid$`PCOS`)
conf_matrix2
# Plot confusion matrix
plot(conf_matrix2$table, col = conf_matrix2$byClass,
main = "Fig. 22 - Confusion Matrix for second kNN Model",
xlab = "Predicted",
ylab = "Actual")
# Calculate accuracy for the new kNN model
knn_accuracy2 <- mean(knn_model2 == valid4$`PCOS`)
knn_accuracy2
# Compare models
model_names <- c("Decision Tree 1","Decision Tree 2",
"Random Forest 1", "Random Forest 2",
"GBM 1", "GBM 2",
"SVM 1", "SVM 2", "Neural Network 1",
"Neural Network 1.2", "Neural Network 2",
"k-NN 1", "k-NN 2")
accuracies <- c(0.8592593, 0.9185185,
0.6296296, 0.9037037,
0.8814815, 0.6222222,
0.9111111, 0.9185185,
0.3037037, 0.6518519, 0.3037037,
0.6518519, 0.8814815)
# place accuracies in data frame
results <- data.frame(Model = model_names, Accuracy = accuracies)
# order in descending order
results <- results[order(results$Accuracy, decreasing = TRUE), ]
# Display the results
kable(results, caption = "<font color=#000000><b>Table 5. </b>Model Comparison </font>", format = "html") %>%
kable_styling(bootstrap_options = c("hover", "condensed"), font_size = 13) %>%
kableExtra::scroll_box(width = "100%", height = "400px")
# set a seed for reproducibility purposes
set.seed(19)
# create the model
# nn_model <- neuralnet(`PCOS`~.,
#                       data = nn_train,
#                       hidden = c(12, 8),  # Specify the number of hidden layers and neurons
#                       linear.output = FALSE,
#                       stepmax = 20000  # Increase the maximum number of iterations
# )
# recreate the first model:
nn_model2 <-  neuralnet(`PCOS`~.,
data=train,
hidden=c(4,1),
linear.output = FALSE,
stepmax = 10000  # Increase the maximum number of iterations
)
# create the plot based on the model above
plot(nn_model2, rep = "best")
grid::grid.text("Fig. 19.2 - First Neural Network Model", x = 0.5, y = 0.1)
#checking the accuracy
check <- as.numeric(valid$`PCOS`) == max.col(pred)
nn_accuracy <-  (sum(check)/nrow(valid))
nn_accuracy
# set seed for reproduction
set.seed(098)
#checking the accuracy
check <- as.numeric(valid$`PCOS`) == max.col(pred)
nn_accuracy <-  (sum(check)/nrow(valid))
nn_accuracy
#plot support vector machine
#plot(svm_model, train)
# Using PCA for dimensionality reduction (assuming 'train' has multiple features)
pca_model <- prcomp(train[, -which(names(train) == "PCOS")])  # PCA on features except target
train_pca <- predict(pca_model, train)
# Plotting the reduced dimensions (first two principal components)
plot(train_pca[, 1], train_pca[, 2], col = train$PCOS, main="Fig.17 - PCA plot for SVM 1 model")
# Compare models
model_names <- c("Decision Tree 1","Decision Tree 2",
"Random Forest 1", "Random Forest 2",
"GBM 1", "GBM 2",
"SVM 1", "SVM 2", "Neural Network 1",
"Neural Network 1.2", "Neural Network 2",
"k-NN 1", "k-NN 2")
accuracies <- c(0.8592593, 0.9185185,
0.6296296, 0.9037037,
0.8814815, 0.6222222,
0.9111111, 0.9185185,
0.3037037, 0.7259259, 0.3037037,
0.6518519, 0.8814815)
# place accuracies in data frame
results <- data.frame(Model = model_names, Accuracy = accuracies)
# order in descending order
results <- results[order(results$Accuracy, decreasing = TRUE), ]
# Display the results
kable(results, caption = "<font color=#000000><b>Table 5. </b>Model Comparison </font>", format = "html") %>%
kable_styling(bootstrap_options = c("hover", "condensed"), font_size = 13) %>%
kableExtra::scroll_box(width = "100%", height = "400px")
# Compare models
model_names <- c("Decision Tree 1","Decision Tree 2",
"Random Forest 1", "Random Forest 2",
"GBM 1", "GBM 2",
"SVM 1", "SVM 2", "Neural Network 1",
"Neural Network 1.2", "Neural Network 2",
"k-NN 1", "k-NN 2")
accuracies <- c(0.8592593, 0.9185185,
0.6296296, 0.9037037,
0.8814815, 0.6222222,
0.9111111, 0.9185185,
0.3037037, 0.7259259, 0.3037037,
0.6518519, 0.8814815)
# place accuracies in data frame
results <- data.frame(Model = model_names, Accuracy = accuracies)
# order in descending order
results <- results[order(results$Accuracy, decreasing = TRUE), ]
# Display the results
kable(results, caption = "<font color=#000000><b>Table 5. </b>Model Comparison </font>", format = "html") %>%
kable_styling(bootstrap_options = c("hover", "condensed"), font_size = 13) %>%
kableExtra::scroll_box(width = "100%", height = "500px")
wd <- "/Users/letisalba/Desktop/Data-698/Final-Presentation-and-Paper/figs:tables/"
knitr::include_graphics(paste0(wd, "fig1.png"))
knitr::include_graphics(paste0(wd, "fig2.png"))
knitr::include_graphics(paste0(wd, "fig2_2.png"))
knitr::include_graphics(paste0(wd, "fig3.png"))
knitr::include_graphics(paste0(wd, "fig3_2.png"))
knitr::include_graphics(paste0(wd, "fig3_3.png"))
knitr::include_graphics(paste0(wd, "fig4.png"))
knitr::include_graphics(paste0(wd, "fig5.png"))
knitr::include_graphics(paste0(wd, "fig6.png"))
knitr::include_graphics(paste0(wd, "fig7.png"))
knitr::include_graphics(paste0(wd, "fig8.png"))
knitr::include_graphics(paste0(wd, "fig9.png"))
knitr::include_graphics(paste0(wd, "fig10.png"))
knitr::include_graphics(paste0(wd, "fig11.png"))
knitr::include_graphics(paste0(wd, "fig12.png"))
knitr::include_graphics(paste0(wd, "fig13.png"))
knitr::include_graphics(paste0(wd, "fig14.png"))
knitr::include_graphics(paste0(wd, "fig15.png"))
knitr::include_graphics(paste0(wd, "fig16.png"))
knitr::include_graphics(paste0(wd, "fig17.png"))
knitr::include_graphics(paste0(wd, "fig18.png"))
knitr::include_graphics(paste0(wd, "fig19.png"))
knitr::include_graphics(paste0(wd, "fig19_2.png"))
knitr::include_graphics(paste0(wd, "fig20.png"))
knitr::include_graphics(paste0(wd, "fig21.png"))
knitr::include_graphics(paste0(wd, "fig22.png"))
knitr::include_graphics(paste0(wd, "table1.png"))
knitr::include_graphics(paste0(wd, "table2.png"))
knitr::include_graphics(paste0(wd, "table3.png"))
knitr::include_graphics(paste0(wd, "table4.png"))
knitr::include_graphics(paste0(wd, "table5.png"))
wd <- "/Users/letisalba/Desktop/Data-698/Final-Presentation-and-Paper/figs:tables/"
knitr::include_graphics(paste0(wd, "fig19.png"))
knitr::include_graphics(paste0(wd, "fig19_2.png"))
knitr::include_graphics(paste0(wd, "fig20.png"))
wd <- "/Users/letisalba/Desktop/Data-698/Final-Presentation-and-Paper/figs:tables/write_up/"
knitr::include_graphics(paste0(wd, "table5_wu.png"))
